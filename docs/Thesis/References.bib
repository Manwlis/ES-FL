%-----------------------------------
%	REFERENCES
%-----------------------------------
@techreport{MEC,
	author =        {Yun Chao Hu and Milan Patel and Dario Sabella and Nurit Sprecher and Valerie Young},
	title =         {Mobile Edge Computing A key technology towards 5G},
	number =        {11},
	institution =   {European Telecommunications Standards Institute},
	address =       {06921 Sophia Antipolis CEDEX, France},
	Abstract =      {Mobile Edge Computing (MEC) is a new technology which is currently being standardized in an ETSI Industry Specification Group (ISG) of the same name. Mobile Edge Computing provides an IT service environment and cloud-computing capabilities at the edge of the mobile network, within the Radio Access Network (RAN) and in close proximity to mobile subscribers. The aim is to reduce latency, ensure highly efficient network operation and service delivery, and offer an improved user experience.},
	keywords =      {Mobile Edge Computing, Multiple-Access Edge Computing, cloud-computing, edge},
	month =         {9},
	year =          {2015},
	numpages =      {16},
	url =           {https://www.etsi.org/images/files/ETSIWhitePapers/etsi_wp11_mec_a_key_technology_towards_5g.pdf},
	isbn =          {979-10-92620-08-5}
}

@article{FL-original-paper,
    doi =           {10.48550/ARXIV.1602.05629},
    url =           {https://arxiv.org/abs/1602.05629},
    author =        {McMahan,  H. Brendan and Moore,  Eider and Ramage,  Daniel and Hampson,  Seth and Arcas,  Blaise Ag\"{u}era y},
    keywords =      {Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Communication-Efficient Learning of Deep Networks from Decentralized Data},
    publisher =     {arXiv},
    year =          {2016},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@article{Xu2021,
    doi =           {10.1109/access.2021.3063291},
    url =           {https://doi.org/10.1109/access.2021.3063291},
    year =          {2021},
    publisher =     {Institute of Electrical and Electronics Engineers ({IEEE})},
    volume =        {9},
    pages =         {38457--38466},
    author =        {Wenyuan Xu and Weiwei Fang and Yi Ding and Meixia Zou and Naixue Xiong},
    title =         {Accelerating Federated Learning for {IoT} in Big Data Analytics With Pruning,  Quantization and Selective Updating},
    journal =       {{IEEE} Access}
}

@article{Wei2020,
    doi =           {10.1109/tifs.2020.2988575},
    url =           {https://doi.org/10.1109/tifs.2020.2988575},
    year =          {2020},
    publisher =     {Institute of Electrical and Electronics Engineers ({IEEE})},
    volume =        {15},
    pages =         {3454--3469},
    author =        {Kang Wei and Jun Li and Ming Ding and Chuan Ma and Howard H. Yang and Farhad Farokhi and Shi Jin and Tony Q. S. Quek and H. Vincent Poor},
    title =         {Federated Learning With Differential Privacy: Algorithms and Performance Analysis},
    journal =       {{IEEE} Transactions on Information Forensics and Security}
}

@article{Mills2020,
    doi =           {10.1109/jiot.2019.2956615},
    url =           {https://doi.org/10.1109/jiot.2019.2956615},
    year =          {2020},
    month =         {8},
    publisher =     {Institute of Electrical and Electronics Engineers ({IEEE})},
    volume =        {7},
    number =        {7},
    pages =         {5986--5994},
    author =        {Jed Mills and Jia Hu and Geyong Min},
    title =         {Communication-Efficient Federated Learning for Wireless Edge Intelligence in {IoT}},
    journal =       {{IEEE} Internet of Things Journal}
}

@inbook{russell_norvig_2003_1,
    author =        {Russell, Stuart J. and Norvig, Peter},
    booktitle =     {Artificial Intelligence: A modern approach},
    edition =       {2},
    isbn =          {0137903952; 9780137903955; 0130803022; 9780130803023},
    % libgen.li/file.php?md5=2965b1a4e080390931391b293954044a
    
    title =         {Introduction},
    pages =         {31–32},
    
    year =          {2003},
    
    publisher =     {Pearson Education, Inc.},
    place =         {Upper Saddle River, New Jersey}
}

@inbook{russell_norvig_2003_18,
    author =        {Russell, Stuart J. and Norvig, Peter},
    booktitle =     {Artificial Intelligence: A modern approach},
    edition =       {2},
    isbn =          {0137903952; 9780137903955; 0130803022; 9780130803023},
    % libgen.li/file.php?md5=2965b1a4e080390931391b293954044a
    
    title =         {Learning from Observations},
    pages =         {649-651},
    
    year =          {2003},
    
    publisher =     {Pearson Education, Inc.},
    place =         {Upper Saddle River, New Jersey}
}

@misc{Transfer_Learning,
    doi =           {10.48550/ARXIV.1911.02685},
    url =           {https://arxiv.org/abs/1911.02685},
    author =        {Zhuang,  Fuzhen and Qi,  Zhiyuan and Duan,  Keyu and Xi,  Dongbo and Zhu,  Yongchun and Zhu,  Hengshu and Xiong,  Hui and He,  Qing},
    keywords =      {Machine Learning (cs.LG),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {A Comprehensive Survey on Transfer Learning},
    publisher =     {arXiv},
    year =          {2019},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@misc{Probabilistic_Reasoning,
    doi =           {10.48550/ARXIV.1303.5718},
    url =           {https://arxiv.org/abs/1303.5718},
    author =        {Geiger,  Dan and Heckerman,  David},
    keywords =      {Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Advances in Probabilistic Reasoning},
    publisher =     {arXiv},
    year =          {2013},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@article{McCulloch1943,
    doi =           {10.1007/bf02478259},
    url =           {https://doi.org/10.1007/bf02478259},
    year =          {1943},
    month =         {12},
    publisher =     {Springer Science and Business Media {LLC}},
    volume =        {5},
    number =        {4},
    pages =         {115--133},
    author =        {Warren S. McCulloch and Walter Pitts},
    title =         {A logical calculus of the ideas immanent in nervous activity},
    journal =       {The Bulletin of Mathematical Biophysics}
}

@incollection{Alexnet,
    author =        {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
    booktitle =     {Advances in Neural Information Processing Systems 25},
    editor =        {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
    keywords =      {cnn deeplearning ma-zehe neuralnet},
    pages =         {1097--1105},
    publisher =     {Curran Associates, Inc.},
    title =         {ImageNet Classification with Deep Convolutional Neural Networks},
    url =           {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
    year =          2012
}

@misc{limits_speech_recognition,
    doi =           {10.48550/ARXIV.2010.10504},
    url =           {https://arxiv.org/abs/2010.10504},
    author =        {Zhang,  Yu and Qin,  James and Park,  Daniel S. and Han,  Wei and Chiu,  Chung-Cheng and Pang,  Ruoming and Le,  Quoc V. and Wu,  Yonghui},
    keywords =      {Audio and Speech Processing (eess.AS),  Machine Learning (cs.LG),  Sound (cs.SD),  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition},
    publisher =     {arXiv},
    year =          {2020},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@misc{natural_language,
    doi =           {10.48550/ARXIV.1807.10854},
    url =           {https://arxiv.org/abs/1807.10854},
    author =        {Otter,  Daniel W. and Medina,  Julian R. and Kalita,  Jugal K.},
    keywords =      {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {A Survey of the Usages of Deep Learning in Natural Language Processing},
    publisher =     {arXiv},
    year =          {2018},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@article{Climatology,
    doi =           {10.1029/2019ms001705},
    url =           {https://doi.org/10.1029/2019ms001705},
    year =          {2019},
    month =         {8},
    publisher =     {American Geophysical Union ({AGU})},
    volume =        {11},
    number =        {8},
    pages =         {2680--2693},
    author =        {Jonathan A. Weyn and Dale R. Durran and Rich Caruana},
    title =         {Can Machines Learn to Predict Weather? Using Deep Learning to Predict Gridded 500-{hPa} Geopotential Height From Historical Weather Data},
    journal =       {Journal of Advances in Modeling Earth Systems}
}

@article{biotechnology,
    doi =           {10.1016/j.tibtech.2018.08.005},
    url =           {https://doi.org/10.1016/j.tibtech.2018.08.005},
    year =          {2019},
    month =         {3},
    publisher =     {Elsevier {BV}},
    volume =        {37},
    number =        {3},
    pages =         {310--324},
    author =        {Jason Riordon and Du{\v{s}}an Sovilj and Scott Sanner and David Sinton and Edmond W.K. Young},
    title =         {Deep Learning with Microfluidics for Biotechnology},
    journal =       {Trends in Biotechnology}
}

@article{dl_evolution,
    doi =           {10.1016/j.cogsys.2018.08.023},
    url =           {https://doi.org/10.1016/j.cogsys.2018.08.023},
    year =          {2018},
    month =         {12},
    publisher =     {Elsevier {BV}},
    volume =        {52},
    pages =         {701--708},
    author =        {Ritika Wason},
    title =         {Deep learning: Evolution and expansion},
    journal =       {Cognitive Systems Research}
}

@inbook{Elgendy2020_ml_feature,
    booktitle =     {Deep learning for vision systems},
    edition =       {1},
    author =        {Elgendy, Mohamed},
    isbn =          {1617296198; 9781617296192},
    % libgen.li/file.php?md5=b26784397a47df876a8a9ef6060d9819
    % https://www.manning.com/books/deep-learning-for-vision-systems
    
    title =         {Feature extraction},
    pages =         {27},
    
    month =         {12},
    year =          {2020},
    
    publisher =     {Manning Publications},
    address =       {New York, NY}
}

@InProceedings{pmlr-v9-glorot10a,
    title = 	    {Understanding the difficulty of training deep feedforward neural networks},
    author = 	    {Glorot, Xavier and Bengio, Yoshua},
    booktitle = 	{Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
    pages = 	    {249--256},
    editor = 	    {Teh, Yee Whye and Titterington, Mike},
    volume = 	    {9},
    series = 	    {Proceedings of Machine Learning Research},
    address = 	    {Chia Laguna Resort, Sardinia, Italy},
    eventdate =     {2010-05-13/2010-05-15},
    publisher =     {PMLR},
    pdf = 	        {http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf},
    url = 	        {https://proceedings.mlr.press/v9/glorot10a.html},
    abstract = 	    {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future.  We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1.  Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.}
}

@article{He_Init_paper,
    author =        {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    title =         {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
    journal =       {CoRR},
    volume =        {abs/1502.01852},
    year =          {2015},
    url =           {http://arxiv.org/abs/1502.01852},
    eprinttype =    {arXiv},
    eprint =        {1502.01852},
    timestamp =     {Wed, 17 Apr 2019 17:23:45 +0200},
    biburl =        {https://dblp.org/rec/journals/corr/HeZR015.bib},
    bibsource =     {dblp computer science bibliography, https://dblp.org}
}

@article{backpropagation_original,
    doi =           {10.1038/323533a0},
    url =           {https://doi.org/10.1038/323533a0},
    year =          {1986},
    month =         {10},
    publisher =     {Springer Science and Business Media {LLC}},
    volume =        {323},
    number =        {6088},
    pages =         {533--536},
    author =        {David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
    title =         {Learning representations by back-propagating errors},
    journal =       {Nature}
}


@InProceedings{nesterov_momentum,
    title = 	    {On the importance of initialization and momentum in deep learning},
    author = 	    {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
    booktitle = 	{Proceedings of the 30th International Conference on Machine Learning},
    pages = 	    {1139--1147},
    year = 	        {2013},
    editor = 	    {Dasgupta, Sanjoy and McAllester, David},
    volume = 	    {28},
    number =        {3},
    series = 	    {Proceedings of Machine Learning Research},
    address = 	    {Atlanta, Georgia, USA},
    month = 	    {01},
    publisher =     {PMLR},
    pdf = 	        {http://proceedings.mlr.press/v28/sutskever13.pdf},
    url = 	        {https://proceedings.mlr.press/v28/sutskever13.html},
    abstract = 	    {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned.     Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.}
}

@ARTICLE{FL_comprehensive_survey, %survey A
    author =        {Lim, Wei Yang Bryan and Luong, Nguyen Cong and Hoang, Dinh Thai and Jiao, Yutao and Liang, Ying-Chang and Yang, Qiang and Niyato, Dusit and Miao, Chunyan},
    journal =       {IEEE Communications Surveys \& Tutorials}, 
    title =         {Federated Learning in Mobile Edge Networks: A Comprehensive Survey}, 
    year =          {2020},
    volume =        {22},
    number =        {3},
    pages =         {2031-2063},
    doi =           {10.1109/COMST.2020.2986024}
 }
 @misc{survey_B,
    doi =           {10.48550/ARXIV.1912.04977},
    url =           {https://arxiv.org/abs/1912.04977},
    author =        {Kairouz,  Peter and McMahan,  H. Brendan and Avent,  Brendan and Bellet,  Aurélien and Bennis,  Mehdi and Bhagoji,  Arjun Nitin and Bonawitz,  Kallista and Charles,  Zachary and Cormode,  Graham and Cummings,  Rachel and D'Oliveira,  Rafael G. L. and Eichner,  Hubert and Rouayheb,  Salim El and Evans,  David and Gardner,  Josh and Garrett,  Zachary and Gascón,  Adrià and Ghazi,  Badih and Gibbons,  Phillip B. and Gruteser,  Marco and Harchaoui,  Zaid and He,  Chaoyang and He,  Lie and Huo,  Zhouyuan and Hutchinson,  Ben and Hsu,  Justin and Jaggi,  Martin and Javidi,  Tara and Joshi,  Gauri and Khodak,  Mikhail and Konečný,  Jakub and Korolova,  Aleksandra and Koushanfar,  Farinaz and Koyejo,  Sanmi and Lepoint,  Tancrède and Liu,  Yang and Mittal,  Prateek and Mohri,  Mehryar and Nock,  Richard and \"{O}zg\"{u}r,  Ayfer and Pagh,  Rasmus and Raykova,  Mariana and Qi,  Hang and Ramage,  Daniel and Raskar,  Ramesh and Song,  Dawn and Song,  Weikang and Stich,  Sebastian U. and Sun,  Ziteng and Suresh,  Ananda Theertha and Tramèr,  Florian and Vepakomma,  Praneeth and Wang,  Jianyu and Xiong,  Li and Xu,  Zheng and Yang,  Qiang and Yu,  Felix X. and Yu,  Han and Zhao,  Sen},
    keywords =      {Machine Learning (cs.LG),  Cryptography and Security (cs.CR),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Advances and Open Problems in Federated Learning},
    publisher =     {arXiv},
    year =          {2019},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@article{survey_C,
    doi =           {10.48550/ARXIV.1902.04885},
    url =           {https://arxiv.org/abs/1902.04885},
    author =        {Yang,  Qiang and Liu,  Yang and Chen,  Tianjian and Tong,  Yongxin},
    keywords =      {Artificial Intelligence (cs.AI),  Cryptography and Security (cs.CR),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Federated Machine Learning: Concept and Applications},
    publisher =     {arXiv},
    year =          {2019},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@article{survey_D,
    title =         {A review of applications in federated learning},
    journal =       {Computers \& Industrial Engineering},
    volume =        {149},
    pages =         {106854},
    year =          {2020},
    issn =          {0360-8352},
    doi =           {https://doi.org/10.1016/j.cie.2020.106854},
    url =           {https://www.sciencedirect.com/science/article/pii/S0360835220305532},
    author =        {Li Li and Yuxi Fan and Mike Tse and Kuo-Yi Lin},
    keywords =      {Federated learning, Literature review, Citation analysis, Research front},
    abstract =      {Federated Learning (FL) is a collaboratively decentralized privacy-preserving technology to overcome challenges of data silos and data sensibility. Exactly what research is carrying the research momentum forward is a question of interest to research communities as well as industrial engineering. This study reviews FL and explores the main evolution path for issues exist in FL development process to advance the understanding of FL. This study aims to review prevailing application in industrial engineering to guide for the future landing application. This study also identifies six research fronts to address FL literature and help advance our understanding of FL for future optimization. This study contributes to conclude application in industrial engineering and computer science and summarize a review of applications in FL.}
}

@article{survey_E,
    doi =           {10.1109/msp.2020.2975749},
    url =           {https://doi.org/10.1109/msp.2020.2975749},
    year =          {2020},
    month =         {05},
    publisher =     {Institute of Electrical and Electronics Engineers ({IEEE})},
    volume =        {37},
    number =        {3},
    pages =         {50--60},
    author =        {Tian Li and Anit Kumar Sahu and Ameet Talwalkar and Virginia Smith},
    title =         {Federated Learning: Challenges,  Methods,  and Future Directions},
    journal =       {{IEEE} Signal Processing Magazine}
}

@misc{GBoard_FL,
    doi =           {10.48550/ARXIV.1811.03604},
    url =           {https://arxiv.org/abs/1811.03604},
    author =        {Hard,  Andrew and Rao,  Kanishka and Mathews,  Rajiv and Ramaswamy,  Swaroop and Beaufays,  Fran\c{c}oise and Augenstein,  Sean and Eichner,  Hubert and Kiddon,  Chloé and Ramage,  Daniel},
    keywords =      {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Federated Learning for Mobile Keyboard Prediction},
    publisher =     {arXiv},
    year =          {2018},
    copyright =     {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

@inproceedings{stragglers,
    author =        {Sprague, Michael and Jalalirad, Amir and Scavuzzo, Marco and Capota, Catalin and Neun, Moritz and Do, Lyman and Kopp, Michael},
    year =          {2019},
    month =         {03},
    pages =         {21-28},
    title =         {Asynchronous Federated Learning for Geospatial Applications},
    isbn =          {978-981-10-0665-4},
    doi =           {10.1007/978-3-030-14880-5_2}
}

@misc{probabilistic_quantization,
    doi =           {10.48550/ARXIV.1510.00149},
    url =           {https://arxiv.org/abs/1510.00149},
    author =        {Han,  Song and Mao,  Huizi and Dally,  William J.},
    keywords =      {Computer Vision and Pattern Recognition (cs.CV),  Neural and Evolutionary Computing (cs.NE),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Deep Compression: Compressing Deep Neural Networks with Pruning,  Trained Quantization and Huffman Coding},
    publisher =     {arXiv},
    year =          {2015},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@inproceedings{observation_parameters,
    title=          {Scalable distributed DNN training using commodity GPU cloud computing},
    author=         {Nikko Strom},
    booktitle=      {INTERSPEECH},
    year=           {2015}
}

@misc{interplay_heterogeneities,
    doi =           {10.48550/ARXIV.1812.06127},
    url =           {https://arxiv.org/abs/1812.06127},
    author =        {Li,  Tian and Sahu,  Anit Kumar and Zaheer,  Manzil and Sanjabi,  Maziar and Talwalkar,  Ameet and Smith,  Virginia},
    keywords =      {Machine Learning (cs.LG),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Federated Optimization in Heterogeneous Networks},
    publisher =     {arXiv},
    year =          {2018},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@inproceedings{model_inversion,
    author =        {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
    title =         {Model Inversion Attacks That Exploit Confidence Information and Basic Countermeasures},
    year =          {2015},
    isbn =          {9781450338325},
    publisher =     {Association for Computing Machinery},
    address =       {New York, NY, USA},
    url =           {https://doi.org/10.1145/2810103.2813677},
    doi =           {10.1145/2810103.2813677},
    abstract =      {Machine-learning (ML) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices, making medical diagnoses, and facial recognition. In a model inversion attack, recently introduced in a case study of linear classifiers in personalized medicine by Fredrikson et al., adversarial access to an ML model is abused to learn sensitive genomic information about individuals. Whether model inversion attacks apply to settings outside theirs, however, is unknown. We develop a new class of model inversion attack that exploits confidence values revealed along with predictions. Our new attacks are applicable in a variety of settings, and we explore two in depth: decision trees for lifestyle surveys as used on machine-learning-as-a-service systems and neural networks for facial recognition. In both cases confidence values are revealed to those with the ability to make prediction queries to models. We experimentally show attacks that are able to estimate whether a respondent in a lifestyle survey admitted to cheating on their significant other and, in the other context, show how to recover recognizable images of people's faces given only their name and access to the ML model. We also initiate experimental exploration of natural countermeasures, investigating a privacy-aware decision tree training algorithm that is a simple variant of CART learning, as well as revealing only rounded confidence values. The lesson that emerges is that one can avoid these kinds of MI attacks with negligible degradation to utility.},
    booktitle =     {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
    pages =         {1322–1333},
    numpages =      {12},
    keywords =      {privacy, machine learning, attacks},
    location =      {Denver, Colorado, USA},
    series =        {CCS '15}
}

@misc{adversarial_attack,
    doi =           {10.48550/ARXIV.1312.6199},
    url =           {https://arxiv.org/abs/1312.6199},
    author =        {Szegedy,  Christian and Zaremba,  Wojciech and Sutskever,  Ilya and Bruna,  Joan and Erhan,  Dumitru and Goodfellow,  Ian and Fergus,  Rob},
    keywords =      {Computer Vision and Pattern Recognition (cs.CV),  Machine Learning (cs.LG),  Neural and Evolutionary Computing (cs.NE),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Intriguing properties of neural networks},
    publisher =     {arXiv},
    year =          {2013},
    copyright =     {Creative Commons Attribution 3.0 Unported}
}

@misc{GAN_attack,
    doi =           {10.48550/ARXIV.1702.07464},
    url =           {https://arxiv.org/abs/1702.07464},
    author =        {Hitaj,  Briland and Ateniese,  Giuseppe and Perez-Cruz,  Fernando},
    keywords =      {Cryptography and Security (cs.CR),  Machine Learning (cs.LG),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning},
    publisher =     {arXiv},
    year =          {2017},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@misc{fashion_mnist,
    doi =           {10.48550/ARXIV.1708.07747},
    author =        {Han Xiao and Kashif Rasul and Roland Vollgraf},
    title =         {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
    journal =       {CoRR},
    volume =        {abs/1708.07747},
    year =          {2017},
    url =           {http://arxiv.org/abs/1708.07747},
    archivePrefix = {arXiv},
    eprint =        {1708.07747},
    timestamp =     {Mon, 13 Aug 2018 16:47:27 +0200},
    biburl =        {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},
    bibsource =     {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{LeNet,
    author=         {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
    journal=        {Proceedings of the IEEE}, 
    title=          {Gradient-based learning applied to document recognition}, 
    year=           {1998},
    volume=         {86},
    number=         {11},
    pages=          {2278-2324},
    doi=            {10.1109/5.726791}
}

@misc{inception_module,
    doi =           {10.48550/ARXIV.1409.4842},
    url =           {https://arxiv.org/abs/1409.4842},
    author =        {Szegedy,  Christian and Liu,  Wei and Jia,  Yangqing and Sermanet,  Pierre and Reed,  Scott and Anguelov,  Dragomir and Erhan,  Dumitru and Vanhoucke,  Vincent and Rabinovich,  Andrew},
    keywords =      {Computer Vision and Pattern Recognition (cs.CV),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Going Deeper with Convolutions},
    publisher =     {arXiv},
    year =          {2014},
    copyright =     {arXiv.org perpetual,  non-exclusive license}
}

@misc{parallel_SGD,
    doi =           {10.48550/ARXIV.1410.7455},
    url =           {https://arxiv.org/abs/1410.7455},
    author =        {Povey,  Daniel and Zhang,  Xiaohui and Khudanpur,  Sanjeev},
    keywords =      {Neural and Evolutionary Computing (cs.NE),  Machine Learning (cs.LG),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
    title =         {Parallel training of DNNs with Natural Gradient and Parameter Averaging},
    publisher =     {arXiv},
    year =          {2014},
    copyright =     {Creative Commons Attribution 3.0 Unported}
}

@misc{tensorflow2015-whitepaper,
    title =         { {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
    url =           {https://www.tensorflow.org/},
    note =          {Software available from tensorflow.org},
    author =        {
        Mart\'{i}n~Abadi and
        Ashish~Agarwal and
        Paul~Barham and
        Eugene~Brevdo and
        Zhifeng~Chen and
        Craig~Citro and
        Greg~S.~Corrado and
        Andy~Davis and
        Jeffrey~Dean and
        Matthieu~Devin and
        Sanjay~Ghemawat and
        Ian~Goodfellow and
        Andrew~Harp and
        Geoffrey~Irving and
        Michael~Isard and
        Yangqing Jia and
        Rafal~Jozefowicz and
        Lukasz~Kaiser and
        Manjunath~Kudlur and
        Josh~Levenberg and
        Dandelion~Man\'{e} and
        Rajat~Monga and
        Sherry~Moore and
        Derek~Murray and
        Chris~Olah and
        Mike~Schuster and
        Jonathon~Shlens and
        Benoit~Steiner and
        Ilya~Sutskever and
        Kunal~Talwar and
        Paul~Tucker and
        Vincent~Vanhoucke and
        Vijay~Vasudevan and
        Fernanda~Vi\'{e}gas and
        Oriol~Vinyals and
        Pete~Warden and
        Martin~Wattenberg and
        Martin~Wicke and
        Yuan~Yu and
        Xiaoqiang~Zheng},
    year =          {2015},
}

@article{Durstenfeld_Fisher_Yates_paper,
    doi =           {10.1145/364520.364540},
    url =           {https://doi.org/10.1145/364520.364540},
    issn =          {0001-0782},
    author =        {Durstenfeld, Richard},
    title =         {Algorithm 235: Random Permutation},
    journal =       {Commun. ACM},
    volume =        {7},
    number =        {7},
    pages =         {420},
    numpages =      {2},
    year =          {1964},
    month =         {07},
    issue_date =    {July 1964},
    publisher =     {Association for Computing Machinery},
    address =       {New York, NY, USA},
}


%-----------------------------------
%	EXTERNAL LINKS
%-----------------------------------

@legislation{GDPR,
    author =        {European Parliament and Council of the European Union},
    title =         {REGULATION (EU) 2016/679 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)},
    institution =   {European Union},
    journal =       {Official Journal of the European Union},
    year =          {2016},
    month =         {05},
    day =           {04},
    url =           {http://data.europa.eu/eli/reg/2016/679/oj},
    urldate = {2022-05-25}
}

@legislation{CCPA,
    author =        {Chau A. and Hertzberg S. and Dodd S.},
    title =         {The California Consumer Privacy Act of 2018},
    institution =   {California State Senate},
    year =          {2018},
    month =         {6},
    day =           {29},
    url =           {https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB375},
    urldate = {2022-05-25}
}

@online{activation_function,
    title =         {How to Choose an Activation Function for Deep Learning},
    author =         {Jason Brownlee},
    year =          {2021},
    month =         {1},
    day =           {22},
    url =           {https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/},
    urldate =       {2022-06-04}
}

@online{dl_history,
    title =         {History of Neural Networks},
    institution =   {Stanford University},
    url =           {https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/index.html},
    urldate =       {2022-06-01}
}

@online{IBM_Neural_Networks,
    institution =   {IBM},
    author =        {IBM Cloud Education},
    title =         {Neural Networks},
    year =          {2020},
    month =         {8},
    day =           {17},
    url =           {https://www.ibm.com/cloud/learn/neural-networks},
    urldate =       {2022-06-04}
}

@online{CS231n_stanford_cnn,
    institution =   {Stanford University},
    title =         {Convolutional Neural Networks for Visual Recognition},
    year =          {2022},
    url =           {https://cs231n.github.io/convolutional-networks/},
    urldate =       {2022-06-05}
}

@online{ML_feature,
    organization =  {Manning Publications},
    title =         {Convolutional Neural Networks for Visual Recognition},
    year =          {2022},
    url =           {https://freecontent.manning.com/the-computer-vision-pipeline-part-4-feature-extraction/},
    urldate =       {2022-06-05}
}

@online{Xavier_initialization,
    author =        {James D. McCaffrey},
    title =         {Neural Network Glorot Initialization},
    year =          {2017},
    month =         {6},
    day =           {21},
    
    url =           {https://jamesmccaffrey.wordpress.com/2017/06/21/neural-network-glorot-initialization/},
    urldate =       {2022-06-11}
}

@online{Glorot_initialization_large,
    author =        {James D. McCaffrey},
    title =         {Neural Network Glorot Initialization},
    organization =  {Visual Studio Magazine},
    
    year =          {2019},
    month =         {5},
    day =           {9},
    
    url =           {https://visualstudiomagazine.com/articles/2019/09/05/neural-network-glorot.aspx},
    urldate =       {2022-06-11}
}

@online{Glorot_He_initialization,
    author =        {Andrew Jones},
    title =         {An Explanation of Xavier Initialization},
    year =          {2015},
    month =         {2},
    day =           {14},
    
    url =           {https://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization},
    urldate =       {2022-06-11}
}

@online{loss_functions,
    title =         {Loss functions},
    organization =  {Peltarion},
    
    url =           {https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions},
    urldate =       {2022-06-11}
}

@online{voronoi_cells,
    author =        {Hristo Hristov},
    title =         {An Introduction to the Voronoi Diagram},
    year =          {2021},
    month =         {11},
    day =           {21},
    
    url =           {https://www.baeldung.com/cs/voronoi-diagram},
    urldate =       {2022-06-11}
}

@online{Backpropagation_wiki,
    title =         {Backpropagation},
    organization =  {Wikipedia},
    year =          {2022},
    month =         {03},
    day =           {11},
    
    url =           {https://en.wikipedia.org/wiki/Backpropagation},
    urldate =       {2022-06-13}
}

@online{gradient_wiki,
    title =         {Gradient},
    organization =  {Wikipedia},
    year =          {2022},
    month =         {05},
    day =           {21},
    
    url =           {https://en.wikipedia.org/wiki/Gradient},
    urldate =       {2022-06-13}
}

@online{IBM_Gradient_Descent,
    title =         {Gradient Descent},
    organization =  {IBM Cloud Education},
    year =          {2020},
    month =         {10},
    day =           {27},
    
    url =           {https://www.ibm.com/cloud/learn/gradient-descent},
    urldate =       {2022-06-14}
}

@online{gradient_descent_wiki,
    title =         {Gradient descent},
    organization =  {Wikipedia},
    year =          {2022},
    month =         {06},
    day =           {06},
    
    url =           {https://en.wikipedia.org/wiki/Gradient_descent},
    urldate =       {2022-06-14}
}

@online{IBM_overfitting,
    title =         {Overfitting},
    organization =  {IBM Cloud Education},
    year =          {2021},
    month =         {03},
    day =           {03},
    
    url =           {https://www.ibm.com/cloud/learn/overfitting},
    urldate =       {2022-06-17}
}

@online{Model_skewing_attacks,
    author =        {Nikhil Joshi},
    title =         {Model Skewing Attacks on Machine Learning Models},
    organization =  {Payatu},
    year =          {2021},
    month =         {02},
    day =           {18},
    
    url =           {https://payatu.com/blog/nikhilj/sec4ml-machine-learning-model-skewing-data-poisoning},
    urldate =       {2022-06-27}
}

@online{feedback_weaponization,
    author =        {Elie Bursztein},
    title =         {Attacks against machine learning — an overview},
    year =          {2018},
    month =         {05},
    
    url =           {https://elie.net/blog/ai/attacks-against-machine-learning-an-overview/#:~:text=impacted\%20your\%20users.-,Feedback\%20weaponization,this\%20fact\%20to\%20their\%20advantage.},
    urldate =       {2022-06-27}
}


@online{MPC,
    title =         {What is Secure Multiparty Computation?},
    organization =  {Inpher},
    
    url =           {https://inpher.io/technology/what-is-secure-multiparty-computation/},
    urldate =       {2022-07-01}
}

@online{digits_mnist,
    author =        {LeCun, Yann and Cortes, Corinna},
    keywords =      {MSc _checked character_recognition mnist network neural},
    title =         {{MNIST} handwritten digit database},
    url =           {http://yann.lecun.com/exdb/mnist/},
    year =          {2010}
}

@online{tff,
    title =         {TensorFlow Federated: Machine Learning on Decentralized Data},
    
    url =           {https://www.tensorflow.org/federated},
    urldate =       {2022-07-08}
}

@online{POSIX_socket,
    title =         {socket(2) — Linux manual page},
    organization =  {man7.org},
    year =          {2021},
    month =         {03},
    day =           {22},
    
    url =           {https://man7.org/linux/man-pages/man2/socket.2.html},
    urldate =       {2022-07-08}
}

@online{bsd,
    title =         {Berkeley Software Distribution},
    organization =  {Wikipedia},
    year =          {2022},
    month =         {05},
    day =           {27},
    
    url =           {https://en.wikipedia.org/wiki/Berkeley_Software_Distribution},
    urldate =       {2022-07-08}
}

@online{TFDS,
    title =         { {TensorFlow Datasets}, A collection of ready-to-use datasets},
    organization =  {TensorFlow},
    howpublished =  {\url{https://www.tensorflow.org/datasets} },
    urldate =       {2022-07-09}
}

@online{dataset_norm,
    title =         {Normalize Data component},
    author =        {Blanca, Li and Peter, Lu},
    organization =  {Microsoft},
    year =          {2021},
    month =         {04},
    day =           {11},
    
    url =           {https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/normalize-data},
    urldate =       {2022-07-09}
}

@online{Python/C_API,
    title =         {Python/C API Reference Manual},
    organization =  {Python Software Foundation},
    year =          {2022},
    month =         {07},
    day =           {11},
    
    url =           {https://docs.python.org/3/c-api/index.html},
    urldate =       {2022-07-11}
}

@online{embedding_python,
    title =         {Embedding Python in Another Application},
    organization =  {Python Software Foundation},
    year =          {2022},
    month =         {07},
    day =           {11},
    
    url =           {https://docs.python.org/3/extending/embedding.html},
    urldate =       {2022-07-11}
}

@online{TF_C_API,
    title =         {TensorFlow in other languages},
    organization =  {Google Inc.},
    year =          {2019},
    month =         {08},
    day =           {21},
    
    url =           {https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/extend/bindings.md},
    urldate =       {2022-07-11}
}


@online{Fisher_Yates_shuffle_wiki,
    title =         {Fisher–Yates shuffle wiki},
    organization =  {Wikipedia},
    year =          {2022},
    month =         {04},
    day =           {14},
    
    url =           {https://en.wikipedia.org/wiki/Fisher\%E2\%80\%93Yates_shuffle},
    urldate =       {2022-08-08}
}

@online{Vitis_unified_software_platform,
    title =         {Vitis unified software platform},
    organization =  {AMD Xilinx},
    year =          {2022},
    
    url =           {https://www.xilinx.com/products/design-tools/vitis/vitis-platform.html#overview},
    urldate =       {2022-10-20}
}

@online{Xilinx_Runtime_Library,
    title =         {Xilinx Runtime Library},
    organization =  {AMD Xilinx},
    year =          {2022},
    
    url =           {https://www.xilinx.com/products/design-tools/vitis/xrt.html},
    urldate =       {2022-10-20}
}

@online{OpenCL,
    title =         {OpenCL overview},
    organization =  {The Khronos® Group Inc.},
    year =          {2022},
    
    url =           {https://www.khronos.org/opencl/},
    urldate =       {2022-11-14}
}

@online{Zynq_UltraScale_overview,
    title =         {Zynq UltraScale+ MPSoC Data Sheet: Overview},
    organization =  {Xilinx Inc.},
    year =          {2021},
    month =         {05},
    day =           {26},
    
    url =           {https://docs.xilinx.com/v/u/en-US/ds891-zynq-ultrascale-plus-overview},
    urldate =       {2022-11-14}
}

@online{XRT_Native_APIs,
    title =         {XRT Native APIs},
    organization =  {Xilinx Inc.},
    year =          {2022},
    month =         {10},
    day =           {7},
    
    url =           {https://xilinx.github.io/XRT/master/html/xrt_native_apis.html},
    urldate =       {2023-02-13}
}

%-----------------------------------
%	Unused references
%-----------------------------------
